{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23942,"sourceType":"datasetVersion","datasetId":17839}],"dockerImageVersionId":30009,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install keras==2.3.1\n!pip install tensorflow==2.1.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:46:20.654916Z","iopub.execute_input":"2024-12-27T01:46:20.655275Z","iopub.status.idle":"2024-12-27T01:47:47.493486Z","shell.execute_reply.started":"2024-12-27T01:46:20.655241Z","shell.execute_reply":"2024-12-27T01:47:47.492719Z"}},"outputs":[{"name":"stdout","text":"Collecting keras==2.3.1\n  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n\u001b[K     |████████████████████████████████| 377 kB 8.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.18.5)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (5.3.1)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.4.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.1.2)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.14.0)\nCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 5.9 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (2.10.0)\nInstalling collected packages: keras-applications, keras\n  Attempting uninstall: keras\n    Found existing installation: Keras 2.4.3\n    Uninstalling Keras-2.4.3:\n      Successfully uninstalled Keras-2.4.3\nSuccessfully installed keras-2.3.1 keras-applications-1.0.8\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\nCollecting tensorflow==2.1.0\n  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n\u001b[K     |████████████████████████████████| 421.8 MB 20 kB/s  eta 0:00:011    |███▏                            | 41.1 MB 1.5 MB/s eta 0:04:20��██▋     | 351.4 MB 80.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.13.0)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.18.5)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.4.1)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.31.0)\nCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n\u001b[K     |████████████████████████████████| 448 kB 65.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.34.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (3.3.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.14.0)\nCollecting tensorboard<2.2.0,>=2.1.0\n  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 60.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.11.2)\nRequirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.2)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.10.0)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nRequirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.0.8)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (0.2.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.1.0) (1.1.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (46.1.3.post20200325)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.14.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.7)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.2.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.9)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.1)\nBuilding wheels for collected packages: gast\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=fc1fbc4ad316c9107a0f877c10825671a39c95aabf2232e1688db0c02b9be207\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built gast\nInstalling collected packages: astor, tensorflow-estimator, tensorboard, gast, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.3.0\n    Uninstalling tensorflow-2.3.0:\n      Successfully uninstalled tensorflow-2.3.0\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\ntensorflow-probability 0.11.0 requires gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\nSuccessfully installed astor-0.8.1 gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport glob\nimport os\n\nfrom keras import Input\nfrom keras.applications import VGG19\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense\nfrom keras.layers import Conv2D, UpSampling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\n\nimport random\nfrom numpy import asarray\nfrom itertools import repeat\n\nimport imageio\nfrom imageio import imread\nfrom PIL import Image\nfrom skimage.transform import resize as imresize\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Tensorflow version \" + tf.__version__)\nprint(\"Keras version \" + tf.keras.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:49:29.781515Z","iopub.execute_input":"2024-12-27T01:49:29.781813Z","iopub.status.idle":"2024-12-27T01:49:32.878294Z","shell.execute_reply.started":"2024-12-27T01:49:29.781790Z","shell.execute_reply":"2024-12-27T01:49:32.877565Z"}},"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow version 2.1.0\nKeras version 2.2.4-tf\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# data path\nTRAIN_PATH = r'../input/kermany2018/OCT2017 /train/'\nVAL_PATH = r'../input/kermany2018/OCT2017 /val/'\nTEST_PATH = r'../input/kermany2018/OCT2017 /test/'\ndata_path = TRAIN_PATH\n\nepochs = 2000\n\n# batch size equals to 8 (due to RAM limits)\nbatch_size = 8\n\n# define the shape of low resolution image (LR) \nlow_resolution_shape = (64, 64, 3)\n\n# define the shape of high resolution image (HR) \nhigh_resolution_shape = (256, 256, 3)\n\n# optimizer for discriminator, generator \ncommon_optimizer = Adam(0.0002, 0.5)\n\n# use seed for reproducible results\nSEED = 2020 \ntf.random.set_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:49:41.459207Z","iopub.execute_input":"2024-12-27T01:49:41.459669Z","iopub.status.idle":"2024-12-27T01:49:42.878339Z","shell.execute_reply.started":"2024-12-27T01:49:41.459630Z","shell.execute_reply":"2024-12-27T01:49:42.877713Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## III. Data\n\nLoad data, process data, EDA","metadata":{}},{"cell_type":"code","source":"def get_train_images(data_path):\n\n    CLASSES = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n    image_list = []\n\n    for class_type in CLASSES:\n        image_list.extend(glob.glob(data_path + class_type + '/*'))\n    \n    return image_list    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:49:58.625767Z","iopub.execute_input":"2024-12-27T01:49:58.626110Z","iopub.status.idle":"2024-12-27T01:49:58.630616Z","shell.execute_reply.started":"2024-12-27T01:49:58.626081Z","shell.execute_reply":"2024-12-27T01:49:58.629822Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def find_img_dims(image_list):\n    \n    min_size = []\n    max_size = []\n    \n    for i in range(len(image_list)):\n        im = Image.open(image_list[i])\n        min_size.append(min(im.size))\n        max_size.append(max(im.size))\n    \n    return min(min_size), max(max_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:50:00.877312Z","iopub.execute_input":"2024-12-27T01:50:00.877617Z","iopub.status.idle":"2024-12-27T01:50:00.882825Z","shell.execute_reply.started":"2024-12-27T01:50:00.877589Z","shell.execute_reply":"2024-12-27T01:50:00.881687Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# get min/max image sizes\n\nimage_list = get_train_images(data_path)\nmin_size, max_size = find_img_dims(image_list)\nprint('The min and max image dims are {} and {} respectively.'\n      .format(min_size, max_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:50:56.495643Z","iopub.execute_input":"2024-12-27T01:50:56.495981Z","iopub.status.idle":"2024-12-27T01:59:05.355547Z","shell.execute_reply.started":"2024-12-27T01:50:56.495952Z","shell.execute_reply":"2024-12-27T01:59:05.354572Z"}},"outputs":[{"name":"stdout","text":"The min and max image dims are 384 and 1536 respectively.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def compute_psnr(original_image, generated_image):\n    \n    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n    psnr = tf.image.psnr(original_image, generated_image, max_val=1.0)\n\n    return tf.math.reduce_mean(psnr, axis=None, keepdims=False, name=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T01:50:48.858830Z","iopub.execute_input":"2024-12-27T01:50:48.859200Z","iopub.status.idle":"2024-12-27T01:50:48.863988Z","shell.execute_reply.started":"2024-12-27T01:50:48.859169Z","shell.execute_reply":"2024-12-27T01:50:48.863289Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def plot_psnr(psnr):\n    \n    psnr_means = psnr['psnr_quality']\n    plt.figure(figsize=(10,8))\n    plt.plot(psnr_means)    \n    plt.xlabel('Epochs')\n    plt.ylabel('PSNR') \n    plt.title('PSNR')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.451186Z","iopub.execute_input":"2024-12-26T17:07:40.451412Z","iopub.status.idle":"2024-12-26T17:07:40.458905Z","shell.execute_reply.started":"2024-12-26T17:07:40.451389Z","shell.execute_reply":"2024-12-26T17:07:40.458288Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def compute_ssim(original_image, generated_image):\n    \n    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n    ssim = tf.image.ssim(original_image, generated_image, max_val=1.0, filter_size=11,\n                          filter_sigma=1.5, k1=0.01, k2=0.03)\n\n    return tf.math.reduce_mean(ssim, axis=None, keepdims=False, name=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.460115Z","iopub.execute_input":"2024-12-26T17:07:40.460408Z","iopub.status.idle":"2024-12-26T17:07:40.469243Z","shell.execute_reply.started":"2024-12-26T17:07:40.460384Z","shell.execute_reply":"2024-12-26T17:07:40.468696Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def plot_ssim(ssim):\n    \n    ssim_means = ssim['ssim_quality']\n\n    plt.figure(figsize=(10,8))\n    plt.plot(ssim_means)\n    plt.xlabel('Epochs')\n    plt.ylabel('SSIM')\n    plt.title('SSIM')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.470403Z","iopub.execute_input":"2024-12-26T17:07:40.470733Z","iopub.status.idle":"2024-12-26T17:07:40.478837Z","shell.execute_reply.started":"2024-12-26T17:07:40.470700Z","shell.execute_reply":"2024-12-26T17:07:40.478200Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def plot_loss(losses):\n\n    d_loss = losses['d_history']\n    g_loss = losses['g_history']\n    \n   \n    plt.figure(figsize=(10,8))\n    plt.plot(d_loss, label=\"Discriminator loss\")\n    plt.plot(g_loss, label=\"Generator loss\")\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title(\"Loss\")    \n    plt.legend()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.479927Z","iopub.execute_input":"2024-12-26T17:07:40.480187Z","iopub.status.idle":"2024-12-26T17:07:40.491044Z","shell.execute_reply.started":"2024-12-26T17:07:40.480149Z","shell.execute_reply":"2024-12-26T17:07:40.490477Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"### IV C. Sampling, saving images","metadata":{}},{"cell_type":"code","source":"def sample_images(image_list, batch_size, high_resolution_shape, low_resolution_shape):\n    \n    \"\"\"\n    Pre-process a batch of training images\n    \"\"\"\n    \n    # image_list is the list of all images\n    # ransom sample a batch of images\n    images_batch = np.random.choice(image_list, size=batch_size)\n    \n    lr_images = []\n    hr_images = []\n    \n\n    for img in images_batch:\n  \n        img1 = imread(img, as_gray=False, pilmode='RGB')\n        #img1 = imread(img, pilmode='RGB')\n        img1 = img1.astype(np.float32)\n        \n        # change the size     \n        img1_high_resolution = imresize(img1, high_resolution_shape)\n        img1_low_resolution = imresize(img1, low_resolution_shape)\n                \n\n        # do a random horizontal flip\n        if np.random.random() < 0.5:\n            img1_high_resolution = np.fliplr(img1_high_resolution)\n            img1_low_resolution = np.fliplr(img1_low_resolution)\n       \n        hr_images.append(img1_high_resolution)\n        lr_images.append(img1_low_resolution)\n        \n   \n    # convert lists into numpy ndarrays\n    return np.array(hr_images), np.array(lr_images)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.492010Z","iopub.execute_input":"2024-12-26T17:07:40.492258Z","iopub.status.idle":"2024-12-26T17:07:40.501644Z","shell.execute_reply.started":"2024-12-26T17:07:40.492234Z","shell.execute_reply":"2024-12-26T17:07:40.500774Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def save_images(original_image, lr_image, sr_image, path):\n    \n    \"\"\"\n    Save LR, HR (original) and generated SR\n    images in one panel \n    \"\"\"\n    \n    fig, ax = plt.subplots(1,3, figsize=(10, 6))\n\n    images = [original_image, lr_image, sr_image]\n    titles = ['HR', 'LR','SR - generated']\n\n    for idx,img in enumerate(images):\n        # (X + 1)/2 to scale back from [-1,1] to [0,1]\n        ax[idx].imshow((img + 1)/2.0, cmap='gray')\n        ax[idx].axis(\"off\")\n    for idx, title in enumerate(titles):    \n        ax[idx].set_title('{}'.format(title))\n        \n    plt.savefig(path)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.502588Z","iopub.execute_input":"2024-12-26T17:07:40.502858Z","iopub.status.idle":"2024-12-26T17:07:40.514176Z","shell.execute_reply.started":"2024-12-26T17:07:40.502817Z","shell.execute_reply":"2024-12-26T17:07:40.513414Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def residual_block(x):\n\n    filters = [64, 64]\n    kernel_size = 3\n    strides = 1\n    padding = \"same\"\n    momentum = 0.8\n    activation = \"relu\"\n\n    res = Conv2D(filters=filters[0], kernel_size=kernel_size, strides=strides, padding=padding)(x)\n    res = Activation(activation=activation)(res)\n    res = BatchNormalization(momentum=momentum)(res)\n\n    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, padding=padding)(res)\n    res = BatchNormalization(momentum=momentum)(res)\n\n    res = Add()([res, x])\n    \n    return res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.515252Z","iopub.execute_input":"2024-12-26T17:07:40.515581Z","iopub.status.idle":"2024-12-26T17:07:40.523960Z","shell.execute_reply.started":"2024-12-26T17:07:40.515547Z","shell.execute_reply":"2024-12-26T17:07:40.523364Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def build_generator():\n    \n    # use 16 residual blocks in generator\n    residual_blocks = 16\n    momentum = 0.8\n    \n    # input LR dimension: 4x downsample of HR\n    input_shape = (64, 64, 3)\n    \n    # input for the generator\n    input_layer = Input(shape=input_shape)\n    \n    # pre-residual block: conv layer before residual blocks \n    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)\n    \n    # add 16 residual blocks\n    res = residual_block(gen1)\n    for i in range(residual_blocks - 1):\n        res = residual_block(res)\n    \n    # post-residual block: conv and batch-norm layer after residual blocks\n    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n    gen2 = BatchNormalization(momentum=momentum)(gen2)\n    \n    # take the sum of pre-residual block(gen1) and post-residual block(gen2)\n    gen3 = Add()([gen2, gen1])\n    \n    # upsampling\n    gen4 = UpSampling2D(size=2)(gen3)\n    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n    gen4 = Activation('relu')(gen4)\n    \n    # upsampling\n    gen5 = UpSampling2D(size=2)(gen4)\n    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n    gen5 = Activation('relu')(gen5)\n    \n    # conv layer at the output\n    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen5)\n    output = Activation('tanh')(gen6)\n    \n    # model \n    model = Model(inputs=[input_layer], outputs=[output], name='generator')\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.524942Z","iopub.execute_input":"2024-12-26T17:07:40.525288Z","iopub.status.idle":"2024-12-26T17:07:40.536518Z","shell.execute_reply.started":"2024-12-26T17:07:40.525255Z","shell.execute_reply":"2024-12-26T17:07:40.535859Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"generator = build_generator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:40.537454Z","iopub.execute_input":"2024-12-26T17:07:40.537672Z","iopub.status.idle":"2024-12-26T17:07:42.064568Z","shell.execute_reply.started":"2024-12-26T17:07:40.537650Z","shell.execute_reply":"2024-12-26T17:07:42.063594Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### V 2. Discriminator","metadata":{}},{"cell_type":"code","source":"def build_discriminator():\n    \n    # define hyperparameters\n    leakyrelu_alpha = 0.2\n    momentum = 0.8\n    \n    # the input is the HR shape\n    input_shape = (256, 256, 3)\n    \n    # input layer for discriminator\n    input_layer = Input(shape=input_shape)\n    \n    # 8 convolutional layers with batch normalization  \n    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n\n    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n    dis2 = BatchNormalization(momentum=momentum)(dis2)\n\n    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n    dis3 = BatchNormalization(momentum=momentum)(dis3)\n\n    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n    dis4 = BatchNormalization(momentum=0.8)(dis4)\n\n    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n    dis5 = BatchNormalization(momentum=momentum)(dis5)\n\n    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n    dis6 = BatchNormalization(momentum=momentum)(dis6)\n\n    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n    dis7 = BatchNormalization(momentum=momentum)(dis7)\n\n    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n    dis8 = BatchNormalization(momentum=momentum)(dis8)\n    \n    # fully connected layer \n    dis9 = Dense(units=1024)(dis8)\n    dis9 = LeakyReLU(alpha=0.2)(dis9)\n    \n    # last fully connected layer - for classification \n    output = Dense(units=1, activation='sigmoid')(dis9)   \n    \n    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:42.065747Z","iopub.execute_input":"2024-12-26T17:07:42.065964Z","iopub.status.idle":"2024-12-26T17:07:42.078071Z","shell.execute_reply.started":"2024-12-26T17:07:42.065943Z","shell.execute_reply":"2024-12-26T17:07:42.077301Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"discriminator = build_discriminator()\ndiscriminator.trainable = True\ndiscriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:42.079015Z","iopub.execute_input":"2024-12-26T17:07:42.079271Z","iopub.status.idle":"2024-12-26T17:07:42.443601Z","shell.execute_reply.started":"2024-12-26T17:07:42.079246Z","shell.execute_reply":"2024-12-26T17:07:42.442944Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### V 3. VGG19 Feature Extractor ","metadata":{}},{"cell_type":"code","source":"VGG19_base = VGG19(weights=\"imagenet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:07:42.444796Z","iopub.execute_input":"2024-12-26T17:07:42.445029Z","iopub.status.idle":"2024-12-26T17:08:14.438937Z","shell.execute_reply.started":"2024-12-26T17:07:42.445005Z","shell.execute_reply":"2024-12-26T17:08:14.438313Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n574717952/574710816 [==============================] - 29s 0us/step\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def build_VGG19():\n    \n    input_shape = (256, 256, 3)\n    VGG19_base.outputs = [VGG19_base.get_layer('block5_conv2').output]\n    input_layer = Input(shape=input_shape)\n    features = VGG19_base(input_layer)\n    model = Model(inputs=[input_layer], outputs=[features])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:08:14.440083Z","iopub.execute_input":"2024-12-26T17:08:14.440442Z","iopub.status.idle":"2024-12-26T17:08:14.445592Z","shell.execute_reply.started":"2024-12-26T17:08:14.440407Z","shell.execute_reply":"2024-12-26T17:08:14.444781Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"fe_model = build_VGG19()\nfe_model.trainable = False\nfe_model.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:08:14.446611Z","iopub.execute_input":"2024-12-26T17:08:14.446843Z","iopub.status.idle":"2024-12-26T17:08:14.525421Z","shell.execute_reply.started":"2024-12-26T17:08:14.446819Z","shell.execute_reply":"2024-12-26T17:08:14.524918Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def build_adversarial_model(generator, discriminator, feature_extractor):\n    \n    # input layer for high-resolution images\n    input_high_resolution = Input(shape=high_resolution_shape)\n\n    # input layer for low-resolution images\n    input_low_resolution = Input(shape=low_resolution_shape)\n\n    # generate high-resolution images from low-resolution images\n    generated_high_resolution_images = generator(input_low_resolution)\n\n    # extract feature maps from generated images\n    features = feature_extractor(generated_high_resolution_images)\n    \n    # make a discriminator non-trainable \n    discriminator.trainable = False\n    discriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n\n    # discriminator will give us a probability estimation for the generated high-resolution images\n    probs = discriminator(generated_high_resolution_images)\n\n    # create and compile \n    adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n    adversarial_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=common_optimizer)\n    \n    return adversarial_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:08:14.526453Z","iopub.execute_input":"2024-12-26T17:08:14.526811Z","iopub.status.idle":"2024-12-26T17:08:14.532480Z","shell.execute_reply.started":"2024-12-26T17:08:14.526770Z","shell.execute_reply":"2024-12-26T17:08:14.531567Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"adversarial_model = build_adversarial_model(generator, discriminator, fe_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:08:14.533405Z","iopub.execute_input":"2024-12-26T17:08:14.533653Z","iopub.status.idle":"2024-12-26T17:08:16.145717Z","shell.execute_reply.started":"2024-12-26T17:08:14.533630Z","shell.execute_reply":"2024-12-26T17:08:16.145063Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## VI. Training \n","metadata":{}},{"cell_type":"code","source":"# initialize \n\nlosses = {\"d_history\":[], \"g_history\":[]}\npsnr = {'psnr_quality': []}\nssim = {'ssim_quality': []}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:08:16.146917Z","iopub.execute_input":"2024-12-26T17:08:16.147303Z","iopub.status.idle":"2024-12-26T17:08:16.151341Z","shell.execute_reply.started":"2024-12-26T17:08:16.147269Z","shell.execute_reply":"2024-12-26T17:08:16.150430Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# training loop\n\nfor epoch in range(epochs):\n\n    d_history = []\n    g_history = []\n    \n    image_list = get_train_images(data_path)\n    \n    \"\"\"\n    Train the discriminator network\n    \"\"\"\n    \n    hr_images, lr_images = sample_images(image_list, \n                                         batch_size=batch_size,\n                                         low_resolution_shape=low_resolution_shape,\n                                         high_resolution_shape=high_resolution_shape)\n    \n    \n    # normalize the images\n    hr_images = hr_images / 127.5 - 1.\n    lr_images = lr_images / 127.5 - 1.\n    \n    # generate high-resolution images from low-resolution images\n    generated_high_resolution_images = generator.predict(lr_images)\n    \n    # generate a batch of true and fake labels \n    real_labels = np.ones((batch_size, 16, 16, 1))\n    fake_labels = np.zeros((batch_size, 16, 16, 1))\n    \n \n    d_loss_real = discriminator.train_on_batch(hr_images, real_labels)\n    d_loss_real =  np.mean(d_loss_real)\n    d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n    d_loss_fake =  np.mean(d_loss_fake)\n    \n    # calculate total loss of discriminator as average loss on true and fake labels\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    losses['d_history'].append(d_loss)\n   \n\n    \"\"\"\n        Train the generator network\n    \"\"\"\n      \n    # sample a batch of images    \n    hr_images, lr_images = sample_images(image_list, \n                                         batch_size=batch_size,\n                                         low_resolution_shape=low_resolution_shape,\n                                         high_resolution_shape=high_resolution_shape)\n    \n    \n    # normalize the images\n    hr_images = hr_images / 127.5 - 1.\n    lr_images = lr_images / 127.5 - 1.\n    \n    \n    \n    # extract feature maps for true high-resolution images\n    image_features = fe_model.predict(hr_images)\n\n\n    \n    # train the generator\n    g_loss = adversarial_model.train_on_batch([lr_images, hr_images],\n                                               [real_labels, image_features])\n    \n    losses['g_history'].append(0.5 * (g_loss[1]))\n    \n    \n    \n    # calculate the psnr  \n    ps = compute_psnr(hr_images, generated_high_resolution_images) \n    psnr['psnr_quality'].append(ps)\n            \n    # calculate the ssim \n    ss = compute_ssim(hr_images, generated_high_resolution_images)   \n    ssim['ssim_quality'].append(ss)\n\n    \n  \n    \"\"\"\n        save and print image samples\n    \"\"\"\n    \n    if epoch % 500 == 0:\n        \n        hr_images, lr_images = sample_images(image_list, \n                                             batch_size=batch_size,\n                                             low_resolution_shape=low_resolution_shape,\n                                             high_resolution_shape=high_resolution_shape)\n    \n    \n        # normalize the images\n        hr_images = hr_images / 127.5 - 1.\n        lr_images = lr_images / 127.5 - 1.\n    \n    \n        generated_images = generator.predict_on_batch(lr_images)\n    \n        for index, img in enumerate(generated_images):\n            if index < 3:   # comment this line to display all the images\n                save_images(hr_images[index], lr_images[index], img,\n                            path=\"/kaggle/working/img_{}_{}\".format(epoch, index))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:08:16.152741Z","iopub.execute_input":"2024-12-26T17:08:16.153062Z","execution_failed":"2024-12-26T19:06:06.635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plots - post training\n\nplot_loss(losses)\nplot_psnr(psnr)\nplot_ssim(ssim)","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T19:06:06.635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save model weights\n\ngenerator.save_weights(\"/kaggle/working/srgan_generator.h5\")\ndiscriminator.save_weights(\"/kaggle/working/srgan_discriminator.h5\")","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-26T19:06:06.635Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## VII. References and further reading\n\n\n<a name=\"ref1\"></a>[1] [Goodfellow et al. 'Generative Adversarial Nets'](https://arxiv.org/pdf/1406.2661.pdf)\n\n<a name=\"ref2\"></a>[2] [Ledig et al. 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'](https://arxiv.org/abs/1609.04802)\n\n<a name=\"ref3\"></a>[3] [Kailash Ahirwar. 'Generative Adversarial Networks Projects'](https://github.com/PacktPublishing/Generative-Adversarial-Networks-Projects)\n\n<a name=\"ref4\"></a>[4] [Saeed Anwar et al. 'A Deep Journey into Super-resolution: A Survey'](https://arxiv.org/pdf/1904.07523.pdf)\n\n<a name=\"ref5\"></a>[5] [Xintao Wang et al. 'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks'](https://arxiv.org/pdf/1809.00219.pdf)","metadata":{}}]}